# -*- coding: utf-8 -*-
"""Day088_HW.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UhCQv_cKNaYa29GT7PnkALL5kFr46aiQ

## Work
1. 請嘗試寫一個 callback 用來記錄各類別在訓練過程中，對驗證集的 True Positive 與 True Negative
"""

import os
import keras

# Disable GPU
os.environ["CUDA_VISIBLE_DEVICES"] = ""

# train, test = keras.datasets.cifar10.load_data()
(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()
print(f'x_train: {x_train.shape}\ny_train: {y_train.shape}\nx_test: {x_test.shape}\ny_test: {y_test.shape}')

## 資料前處理
def preproc_x(x, flatten=True):
    x = x / 255.
    if flatten:
        x = x.reshape((len(x), -1))
    return x

def preproc_y(y, n_classes=10):
    if y.shape[-1] == 1:
        y = keras.utils.to_categorical(y, n_classes)
    return y

# Preproc the inputs
x_train = preproc_x(x_train)
x_test = preproc_x(x_test)

# Preprc the outputs
y_train = preproc_y(y_train)
y_test = preproc_y(y_test)
print(f'x_train: {x_train.shape}\ny_train: {y_train.shape}\nx_test: {x_test.shape}\ny_test: {y_test.shape}')

from keras.layers import BatchNormalization
def build_mlp(input_data, output_data, n_neurons=[512, 256, 256, 256, 128]):
    """
    TO DO:
    Build your own model
    """
    input_layer = keras.layers.Input([input_data.shape[-1]], name='input-layer')
    for i, n_unit in enumerate(n_neurons):
        if i == 0:
            x = keras.layers.Dense(units=n_unit, activation='relu', name='hidden-layer'+str(i+1))(input_layer)
        else:
            x = keras.layers.Dense(units=n_unit, activation='relu', name='hidden-layer'+str(i+1))(x)
    output_layer = keras.layers.Dense(units=output_data.shape[-1], activation='softmax', name='output-layer')(x)
    model = keras.models.Model(inputs=[input_layer], outputs=[output_layer])
    return model
model = build_mlp(x_train, y_train)
model.summary()

## 超參數設定
LEARNING_RATE = 1e-3
EPOCHS = 25
BATCH_SIZE = 1024
MOMENTUM = 0.95

# 載入 Callbacks
from keras.callbacks import Callback
from sklearn.metrics import confusion_matrix

# Record_fp_tp
class Record_tp_tn(Callback):
    """Define a callback function to collect tp/tn, named Record_fp_tp.
    
    """
    def on_train_begin(self, epoch, logs = {}):
        logs = logs or {}
        record_items = ["val_auc", "val_f1sc", "val_fp", "val_fn", "val_tp", "val_tn"]
        for i in record_items:
            if i not in self.params['metrics']:
                self.params['metrics'].append(i)
    
    def on_epoch_end(self, epoch, logs = {}, thres=0.5):
        logs = logs or {}
        y_true = self.validation_data[1].argmax(axis = 1)
        y_pred = self.model.predict(self.validation_data[0])
        y_pred = (y_pred[:, 1] >= thres) * 1
        
        CM=confusion_matrix(y_true, y_pred)
        logs['val_tp'] =CM[0][0]
        logs['val_tn'] =CM[1][1]
        
rec_tptn = Record_tp_tn()

model = build_mlp(x_train, y_train)
model.summary()
optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM)
model.compile(loss="categorical_crossentropy", metrics=["accuracy"], optimizer=optimizer)

"""
To do:
Fit the model with rec_tptn callback_fn
"""
model.fit(x_train, y_train, 
          epochs=EPOCHS, 
          batch_size=BATCH_SIZE, 
          validation_data=(x_test, y_test),
          callbacks=[rec_tptn],
          shuffle=True
         )

# Collect results
train_loss = model.history.history["loss"]
valid_loss = model.history.history["val_loss"]
train_acc = model.history.history["acc"]
valid_acc = model.history.history["val_acc"]

"""
To do:
Collect tp/tn from model history
"""
valid_tp = model.history.history["val_tp"]
valid_tn = model.history.history["val_tn"]

import matplotlib.pyplot as plt
# %matplotlib inline

plt.plot(range(len(train_loss)), train_loss, label="train loss")
plt.plot(range(len(valid_loss)), valid_loss, label="valid loss")
plt.legend()
plt.title("Loss")
plt.show()

plt.plot(range(len(train_acc)), train_acc, label="train accuracy")
plt.plot(range(len(valid_acc)), valid_acc, label="valid accuracy")
plt.legend()
plt.title("Accuracy")
plt.show()

plt.plot(range(len(valid_tp)), valid_tp, label="valid tp", color="navy")
plt.plot(range(len(valid_tn)), valid_tn, label="valid tn", color="red")
plt.legend()
plt.title("True positives and True Negatives")
plt.show()