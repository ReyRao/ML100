# -*- coding: utf-8 -*-
"""Day76-Optimizer_HW.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QvKnm6Vvn9Y2pRFZGGfIspjIz-XDNEN7

Optimizer
"""

import numpy as np
import keras

# 由於mist的輸入數據維度是(num, 28 , 28)，這裡需要把後面的維度直接拼起來變成784維   

# analyze data
(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()
print(f"X_train shape: {X_train.shape}\ny_train shape: {y_train.shape}")
X_train = X_train.reshape(X_train.shape[0], X_train.shape[1] * X_train.shape[2])
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1] * X_test.shape[2])
print('after reshape:\n')
print(f"X_train shape: {X_train.shape}\ny_train shape: {y_train.shape}")

Y_train = (np.arange(10) == y_train[:, None]).astype(int)
Y_test = (np.arange(10) == y_test[:, None]).astype(int)
print(f"Y_train shape: {Y_train.shape}")

#create neural network layers

def mlp(data, label):
    input_layer = keras.layers.Input([data.shape[-1]])
    x = keras.layers.Dense(units=512, activation='relu')(input_layer)
    for i in [256, 256]:
        x = keras.layers.Dense(units=i, activation='relu')(x)
    output_layer = keras.layers.Dense(units=label.shape[-1], activation='softmax')(x)
    
    model = keras.models.Model(inputs=[input_layer], outputs=output_layer)
    return model

model = mlp(X_train, Y_train)

# 輸出模型摘要資訊
model.summary()

# 第三步：編譯, 
model.compile(optimizer = 'SGD', loss = 'binary_crossentropy', metrics = ['accuracy'])

# # 第五步：訓練, 修正 model 參數
# #Blas GEMM launch failed , 避免動態分配GPU / CPU, 出現問題
# import tensorflow as tf
# gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)
# sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))

batch_size = 512
epochs = 20

history = model.fit(X_train,Y_train,batch_size = batch_size, epochs=epochs, shuffle=True,verbose=2,validation_split=0.3 )

#    第六步：輸出
 
print ( " test set " )
scores = model.evaluate(X_test,Y_test,batch_size=200,verbose= 0)
print ( "" )
#print ( " The test loss is %f " % scores)
print ( " The test loss is %f ", scores)
result = model.predict(X_test,batch_size=200,verbose= 0)

result_max = np.argmax(result, axis = 1 )
test_max = np.argmax(Y_test, axis = 1 )

result_bool = np.equal(result_max, test_max)
true_num = np.sum(result_bool)
print ( "" )
print ( " The accuracy of the model is %f " % (true_num/len(result_bool)))

import matplotlib.pyplot as plt

# %matplotlib inline

# history = model.fit(x, y, validation_split=0.25, epochs=50, batch_size=16, verbose=1)

# Plot training & validation accuracy values
plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

# Plot training & validation loss values
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

